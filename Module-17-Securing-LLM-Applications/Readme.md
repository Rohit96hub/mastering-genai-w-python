# 🔐 Module-17: Securing LLM Applications

This module is dedicated to understanding and mitigating **security risks in Large Language Model (LLM)** based applications. You'll explore key vulnerabilities such as **Information Leakage** and **Prompt Injection**, and learn defensive techniques to safeguard LLM-powered systems.

---

## 🧪 Included Topics

| 🔢 | Topic           | 🔍 Focus Area            | 🧾 Description                                                                 |
|----|-----------------|--------------------------|--------------------------------------------------------------------------------|
| 1  | Information-Leak | 🧠 Data Leakage Risks    | Demonstrates how sensitive data (Aadhar number) can leak from LLMs if not properly sanitized or restricted. |
| 2  | Prompt-Injection | 🎭 Adversarial Prompts   | Shows how attackers can override system instructions and manipulate LLM responses using cleverly crafted user inputs. |

---

