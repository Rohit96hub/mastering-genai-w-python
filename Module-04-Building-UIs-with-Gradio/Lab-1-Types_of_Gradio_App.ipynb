{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Types of Gradio Apps**\n",
        "\n",
        " - **Interface-based (Simple)**\n",
        " - **Blocks-based (Flexible)**\n",
        " - **ChatInterface-based (chatbot kind look)**\n"
      ],
      "metadata": {
        "id": "x-Fi7c3C3xw5"
      },
      "id": "x-Fi7c3C3xw5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Interface-based (Simple)**\n",
        "\n",
        "- Uses gr.Interface()\n",
        "\n",
        "- Good for quick prototypes with 1 input â†’ 1 output\n",
        "\n",
        "- Easy to write, but less customizable"
      ],
      "metadata": {
        "id": "KDLjmnbiAAKr"
      },
      "id": "KDLjmnbiAAKr"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio openai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3YwIiza50aG",
        "outputId": "d1b152c8-8493-423c-ffcc-b7efc7f881a3"
      },
      "id": "A3YwIiza50aG",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31aa677f-4d12-463b-be39-abcc6afc2c16",
      "metadata": {
        "id": "31aa677f-4d12-463b-be39-abcc6afc2c16"
      },
      "source": [
        "####**Import the Gradio module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca2ab939-c0ad-4019-bcca-5b96b71b9dc6",
      "metadata": {
        "id": "ca2ab939-c0ad-4019-bcca-5b96b71b9dc6"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c59af320-80fd-4b30-be24-ec172802deaa",
      "metadata": {
        "id": "c59af320-80fd-4b30-be24-ec172802deaa"
      },
      "source": [
        "####**Create generic Python Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f2de0c11-8f89-4075-ae35-858cfe86f3e5",
      "metadata": {
        "id": "f2de0c11-8f89-4075-ae35-858cfe86f3e5"
      },
      "outputs": [],
      "source": [
        "def reverse_text(text):\n",
        "    return text[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f4dd103d-0952-4a52-8cdb-3bff04fb7909",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f4dd103d-0952-4a52-8cdb-3bff04fb7909",
        "outputId": "9eee360b-e981-41d4-a6b6-656026e7d382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'olleh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "reverse_text(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7168031-f6ae-4db4-801d-44fb2d904c48",
      "metadata": {
        "id": "f7168031-f6ae-4db4-801d-44fb2d904c48"
      },
      "source": [
        "####**Create the Gradio Interface and refer the Function created in last step**\n",
        "\n",
        "- Content of `inputs` textbox would be send as the input to the function and output would be returned in `outputs` textbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a0084b21-0c31-4fbb-8307-80100ade3c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "a0084b21-0c31-4fbb-8307-80100ade3c2f",
        "outputId": "48937c36-7227-4869-80cf-14c7220d364f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dffd4a2e8715edc4ff.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dffd4a2e8715edc4ff.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "gr.Interface(fn=reverse_text, inputs=\"textbox\", outputs=\"textbox\").launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d9dcfdfb-d1cf-4e1b-a7a0-de9b0ccf5804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "d9dcfdfb-d1cf-4e1b-a7a0-de9b0ccf5804",
        "outputId": "8e2b6b8e-6b71-4c18-875b-23a411af088b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://635e41870c447d4d41.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://635e41870c447d4d41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "gr.Interface(fn=reverse_text, inputs=\"textbox\", outputs=\"textbox\").launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e13b4058-5a73-4764-bc23-90708f1e611a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "e13b4058-5a73-4764-bc23-90708f1e611a",
        "outputId": "569c7336-cb0e-46bb-ef54-0c1cb374c804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://74407f79585be14c4b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://74407f79585be14c4b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Inputs and Outputs\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=reverse_text,\n",
        "    inputs=[gr.Textbox(label=\"Employee Name:\", lines=2)],\n",
        "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Retrive API key from Secrets and Set as an ENV**"
      ],
      "metadata": {
        "id": "dyT_i2HIY9s-"
      },
      "id": "dyT_i2HIY9s-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the API key from Colab's secrets\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "cSHWes1CY8BG"
      },
      "id": "cSHWes1CY8BG",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d9cc2da7-8e87-4a54-bda0-8c929612a5fc",
      "metadata": {
        "id": "d9cc2da7-8e87-4a54-bda0-8c929612a5fc"
      },
      "outputs": [],
      "source": [
        "# Set OPENAI_API_KEY as an ENV\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Blocks-based (Flexible)**\n",
        "- Uses gr.Blocks()\n",
        "\n",
        "- Supports multi-step workflows, conditional layouts, multiple models\n",
        "\n",
        "- Best for apps with files, multiple inputs/outputs, or dynamic UI"
      ],
      "metadata": {
        "id": "DkhbVeb96ww3"
      },
      "id": "DkhbVeb96ww3"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "453c1cfa-d0a1-4b5b-b375-0426ef4a66f4",
      "metadata": {
        "id": "453c1cfa-d0a1-4b5b-b375-0426ef4a66f4"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f0d1a9c2-89be-4388-a5ea-1de10a17c425",
      "metadata": {
        "id": "f0d1a9c2-89be-4388-a5ea-1de10a17c425"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_openai(prompt, model_choice):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model_choice,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Respond in 30 words only.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "tl5fDgUx7z29"
      },
      "id": "tl5fDgUx7z29",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Chat with OpenAI (Multiple Blocks Example)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        user_input = gr.Textbox(label=\"Your Question\", lines=2, placeholder=\"Ask me anything...\")\n",
        "        model_choice = gr.Dropdown(\n",
        "            choices=[\"gpt-4o\", \"gpt-4o-mini\", \"gpt-3.5-turbo\"],\n",
        "            label=\"Choose Model\",\n",
        "            value=\"gpt-4o\"\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"Submit\")\n",
        "        clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "    output = gr.Textbox(label=\"AI Response\", lines=4)\n",
        "    status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "    def on_submit(prompt, model):\n",
        "        status_text = \"Response is Generated...\"\n",
        "        return status_text, ask_openai(prompt, model)\n",
        "\n",
        "    submit_btn.click(on_submit, inputs=[user_input, model_choice], outputs=[status, output])\n",
        "    clear_btn.click(lambda: (\"\", \"\", \"\"), inputs=None, outputs=[user_input, output, status])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "-D5Ct47g782_",
        "outputId": "bafea39d-a636-4f5f-806c-2d2991a342c1"
      },
      "id": "-D5Ct47g782_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cc93af46b106b8095f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cc93af46b106b8095f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. ChatInterface Based Gradio App**\n",
        "- It includes Conversational gr.ChatInterface\n",
        "- Look and feel like chatbot with history"
      ],
      "metadata": {
        "id": "vWCTvgY4FL9i"
      },
      "id": "vWCTvgY4FL9i"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fQeNJkzFGS1G"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI"
      ],
      "id": "fQeNJkzFGS1G"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H3a_AUbPGS1G"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI()"
      ],
      "id": "H3a_AUbPGS1G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot function using GPT-3.5 or GPT-4\n",
        "def chatbot(user_message, history):\n",
        "    # Convert Gradio history format to OpenAI messages\n",
        "    messages = [{\"role\": \"system\", \"content\": \"Respond in 30 words only.\"}]\n",
        "\n",
        "    for user, assistant in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "CkicK93vF0gF"
      },
      "id": "CkicK93vF0gF",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio ChatInterface\n",
        "chatbot_ui = gr.ChatInterface(fn=chatbot,\n",
        "                              title=\"ðŸ§  GPT-Powered ChatBot\",\n",
        "                              theme=\"default\")\n",
        "\n",
        "chatbot_ui.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "-JXJdPhnJJ4Q",
        "outputId": "8ef40b7a-f6b8-4b4c-9d78-8752c67b4111"
      },
      "id": "-JXJdPhnJJ4Q",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://992a5a94060804e37d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://992a5a94060804e37d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
