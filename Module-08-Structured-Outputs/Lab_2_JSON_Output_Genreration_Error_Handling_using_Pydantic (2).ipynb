{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Calculate Employee's Term Life Insurance as per the Payscale**\n",
        "\n",
        "###**Reliable JSON Output Generation with LLM, Parsing the JSON output for error handling & Pydantic (for JSON Schema Validation)**\n",
        "\n",
        "#####**✅ Problem:**\n",
        "\n",
        "When interacting with LLMs, we often want structured output (like JSON) rather than freeform text. However, models may produce output that:\n",
        "\n",
        "- Is not valid JSON.\n",
        "\n",
        "- Does not follow a pre-defined schema.\n",
        "\n",
        "- Fails integration with downstream systems expecting structured data.\n",
        "\n",
        "#####**🛠️ Solution:**\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "\n",
        "- Prompt the LLM to return JSON output explicitly.\n",
        "\n",
        "- Use JSON Schema to validate the structure of the output.\n",
        "\n",
        "- Handle model responses gracefully when schema validation fails.\n",
        "\n",
        "#####**Example Techniques Used:**\n",
        "\n",
        "- Prompt engineering for instructing the LLM to produce JSON.\n",
        "\n",
        "- Validation via jsonschema module."
      ],
      "metadata": {
        "id": "SUid2-yaD8Sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**0. Install Dependencies**"
      ],
      "metadata": {
        "id": "4dWIMoBlGnd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qbw79rSNGuAt",
        "outputId": "6512d29a-b680-40c7-ac29-a851c59e116e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Import Required Modules**"
      ],
      "metadata": {
        "id": "B40xz4ELGfEI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m5czD9KVD7Eo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Dict\n",
        "from pydantic import BaseModel, ValidationError, RootModel\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Get API key from Secret**"
      ],
      "metadata": {
        "id": "Iwcm5J8i7b66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Retrieve the API key from Colab's secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "vi_SQXuI-ElE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Set Up OpenAI Client**"
      ],
      "metadata": {
        "id": "sJBIAfZfGxhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "sRXBBbr6HDnr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JSON Output Generation\n",
        "prompt = \"\"\"\n",
        "Generate name, age, payscale and city of 5 employees like employee1, employee2 etc.\n",
        "Respond ONLY with a JSON object.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "output = response.choices[0].message.content.strip()\n",
        "print(\"Raw output:\\n\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eY7DLUKr3Kb",
        "outputId": "fc508a66-70a6-4d87-f654-e755b22054ff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            " {\n",
            "  \"employee1\": {\n",
            "    \"name\": \"John Doe\",\n",
            "    \"age\": 30,\n",
            "    \"payscale\": \"$50,000\",\n",
            "    \"city\": \"New York\"\n",
            "  },\n",
            "  \"employee2\": {\n",
            "    \"name\": \"Jane Smith\",\n",
            "    \"age\": 28,\n",
            "    \"payscale\": \"$45,000\",\n",
            "    \"city\": \"Los Angeles\"\n",
            "  },\n",
            "  \"employee3\": {\n",
            "    \"name\": \"Mike Johnson\",\n",
            "    \"age\": 35,\n",
            "    \"payscale\": \"$60,000\",\n",
            "    \"city\": \"Chicago\"\n",
            "  },\n",
            "  \"employee4\": {\n",
            "    \"name\": \"Emily Wilson\",\n",
            "    \"age\": 26,\n",
            "    \"payscale\": \"$40,000\",\n",
            "    \"city\": \"Houston\"\n",
            "  },\n",
            "  \"employee5\": {\n",
            "    \"name\": \"Alex Rodriguez\",\n",
            "    \"age\": 32,\n",
            "    \"payscale\": \"$55,000\",\n",
            "    \"city\": \"Miami\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string to dictionary\n",
        "data = json.loads(output)"
      ],
      "metadata": {
        "id": "YaEh0SIot0a4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceJabY1muUbR",
        "outputId": "b126abdd-3660-4ad0-db8a-2e3c5c23ea97"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'employee1': {'name': 'John Doe', 'age': 30, 'payscale': '$50,000', 'city': 'New York'}, 'employee2': {'name': 'Jane Smith', 'age': 28, 'payscale': '$45,000', 'city': 'Los Angeles'}, 'employee3': {'name': 'Mike Johnson', 'age': 35, 'payscale': '$60,000', 'city': 'Chicago'}, 'employee4': {'name': 'Emily Wilson', 'age': 26, 'payscale': '$40,000', 'city': 'Houston'}, 'employee5': {'name': 'Alex Rodriguez', 'age': 32, 'payscale': '$55,000', 'city': 'Miami'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access employee1's salary to calculate term life insurance provided ny company\n",
        "print(\"Employee1 Term life insurance:\", data[\"employee1\"][\"payscale\"]*4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhP2qhC1sNfM",
        "outputId": "a65d61ff-c76e-46f1-8bfa-b048702f71ac"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee1 Term life insurance: $50,000$50,000$50,000$50,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. Define Pydantic Models**"
      ],
      "metadata": {
        "id": "VdGDTAxmHuro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PersonInfo(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    payscale: int\n",
        "    city: str\n",
        "\n",
        "# Using RootModel to support JSON like {\"employee1\": {...}, \"employee2\": {...}}\n",
        "class EmployeeDict(RootModel[Dict[str, PersonInfo]]):\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "251su8AWH07s"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, field_validator\n",
        "import re\n",
        "\n",
        "class PersonInfo(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    payscale: int\n",
        "    city: str\n",
        "\n",
        "    @field_validator('payscale', mode='before')\n",
        "    @classmethod\n",
        "    def parse_payscale(cls, v):\n",
        "        if isinstance(v, int):\n",
        "            return v\n",
        "        if isinstance(v, str):\n",
        "            # Remove $ and commas\n",
        "            cleaned = re.sub(r'[^\\d]', '', v)\n",
        "            return int(cleaned)\n",
        "        raise ValueError(\"Invalid payscale format\")\n",
        "\n",
        "class EmployeeDict(RootModel[Dict[str, PersonInfo]]):\n",
        "    pass"
      ],
      "metadata": {
        "id": "Aj8kZVqBxeDD"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Compose Prompt and Call GPT**\n",
        "- JSON Output Generation\n",
        "- Parsing the JSON output for error handling\n",
        "- Schema validation"
      ],
      "metadata": {
        "id": "IB4Mgek4H-WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#JSON Output Generation\n",
        "prompt = \"\"\"\n",
        "Generate name, age, payscale and city of 5 employees like employee1, employee2 etc.\n",
        "Respond ONLY with a JSON object.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    output = response.choices[0].message.content.strip()\n",
        "    print(\"Raw output:\\n\", output)\n",
        "\n",
        "    try:\n",
        "        #Parsing the JSON output for error handling\n",
        "        data = json.loads(output)\n",
        "        # Schema validation\n",
        "        validated_data = EmployeeDict.model_validate(data)\n",
        "        print(\"\\n✅ Validated Data:\\n\", validated_data.model_dump())\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"❌ JSON parsing failed:\", e)\n",
        "    except ValidationError as ve:\n",
        "        print(\"❌ Validation failed:\", ve)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"OpenAI API error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdXFtSlqIJxV",
        "outputId": "427e00de-e2f5-4633-d187-b611f393c6db"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            " {\n",
            "  \"employee1\": {\n",
            "    \"name\": \"John Doe\",\n",
            "    \"age\": 28,\n",
            "    \"payscale\": \"$50,000\",\n",
            "    \"city\": \"New York\"\n",
            "  },\n",
            "  \"employee2\": {\n",
            "    \"name\": \"Jane Smith\",\n",
            "    \"age\": 35,\n",
            "    \"payscale\": \"$60,000\",\n",
            "    \"city\": \"Los Angeles\"\n",
            "  },\n",
            "  \"employee3\": {\n",
            "    \"name\": \"Michael Johnson\",\n",
            "    \"age\": 30,\n",
            "    \"payscale\": \"$55,000\",\n",
            "    \"city\": \"Chicago\"\n",
            "  },\n",
            "  \"employee4\": {\n",
            "    \"name\": \"Emily Davis\",\n",
            "    \"age\": 25,\n",
            "    \"payscale\": \"$45,000\",\n",
            "    \"city\": \"San Francisco\"\n",
            "  },\n",
            "  \"employee5\": {\n",
            "    \"name\": \"Sam Wilson\",\n",
            "    \"age\": 33,\n",
            "    \"payscale\": \"$70,000\",\n",
            "    \"city\": \"Houston\"\n",
            "  }\n",
            "}\n",
            "\n",
            "✅ Validated Data:\n",
            " {'employee1': {'name': 'John Doe', 'age': 28, 'payscale': 50000, 'city': 'New York'}, 'employee2': {'name': 'Jane Smith', 'age': 35, 'payscale': 60000, 'city': 'Los Angeles'}, 'employee3': {'name': 'Michael Johnson', 'age': 30, 'payscale': 55000, 'city': 'Chicago'}, 'employee4': {'name': 'Emily Davis', 'age': 25, 'payscale': 45000, 'city': 'San Francisco'}, 'employee5': {'name': 'Sam Wilson', 'age': 33, 'payscale': 70000, 'city': 'Houston'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = validated_data.model_dump()"
      ],
      "metadata": {
        "id": "yfxyo-igwNzz"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict['employee1']['payscale'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr0EERBUzDu-",
        "outputId": "a427746a-fa60-4ad9-ea04-1947d4e4e8fe"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply employee1's salary by 4\n",
        "print(\"\\n💰 Calculate employee1's Term Life insurance:\\n\", data_dict['employee1']['payscale']*4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVqszhdqyk1U",
        "outputId": "0ff7d23e-0eff-463c-d534-a3f67e774276"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💰 Calculate employee1's Term Life insurance:\n",
            " 200000\n"
          ]
        }
      ]
    }
  ]
}