{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Function Calling to Generate JSON data**\n",
        "\n",
        " #### **‚úÖ Problem:**\n",
        "\n",
        "LLMs often generate unstructured or loosely structured responses. This makes it hard to reliably extract data for downstream processing. Simply prompting the model to output JSON is not reliable, especially in complex scenarios.\n",
        "\n",
        "**Challenge:** How can we get structured, validated JSON output reliably from a language model?\n",
        "\n",
        "\n",
        "####**üõ†Ô∏è Solution:**\n",
        "\n",
        "This lab demonstrates the use of OpenAI Function Calling, a mechanism where:\n",
        "\n",
        "- You define a function signature (including parameter names, types, and descriptions).\n",
        "\n",
        "- The model is guided to generate arguments in JSON format that match the signature.\n",
        "\n",
        "- OpenAI automatically parses this into structured data you can pass to real functions.\n",
        "\n",
        "\n",
        "Think of this as a contract-driven way of interacting with LLMs."
      ],
      "metadata": {
        "id": "Y4Mn2RjE7FYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Install Dependencies**"
      ],
      "metadata": {
        "id": "nqiYvlC67VSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ei5qF7Su9bCX",
        "outputId": "64f90c21-bc1b-46b2-cdf2-35e6d809996c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Retrive API key from Secrets and Set as an ENV**"
      ],
      "metadata": {
        "id": "DJ3S5EdRjta3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the API key from Colab's secrets\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "2e9pCKKNjhdQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set OPENAI_API_KEY as an ENV\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "kMMbhupij3sc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a6f54021-df8f-4552-b07b-9c1bc9a0be7a"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client=OpenAI()"
      ],
      "metadata": {
        "id": "piIyVENMM4dx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Python Code**"
      ],
      "metadata": {
        "id": "WeatNbut7kJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sx8qvWB878o",
        "outputId": "168430bc-332e-443b-f56f-3a9092a459dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Ritu Patil', 'age': 30, 'salary': 35000, 'city': 'Chicago'}\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Extract name, age, and city from the sentence: Ritu Patil is 30 and lives in Chicago. she earns $35000 per year\",\n",
        "        }\n",
        "    ],\n",
        "    tools=[\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"extract_person_info\",\n",
        "                \"description\": \"Extract name, age, and city from text\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"name\": {\"type\": \"string\"},\n",
        "                        \"age\": {\"type\": \"integer\"},\n",
        "                        \"salary\": {\"type\": \"integer\"},\n",
        "                       # \"salary\": {\"type\": \"string\"},\n",
        "                        \"city\": {\"type\": \"string\"},\n",
        "                    },\n",
        "                    \"required\": [\"name\", \"age\",\"salary\",\"city\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ],\n",
        "    tool_choice=\"auto\",\n",
        ")\n",
        "\n",
        "# Extract the structured response\n",
        "tool_calls = response.choices[0].message.tool_calls\n",
        "arguments = tool_calls[0].function.arguments\n",
        "\n",
        "import json\n",
        "parsed = json.loads(arguments)\n",
        "print(parsed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Yearly Bonus = $\", parsed['salary']*2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr6g3bO3q67N",
        "outputId": "09a1b05b-e009-4a71-8e7b-0441828422dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yearly Bonus = $ 70000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parsed['age']*2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9M-wHrtqRwH",
        "outputId": "802c669f-562b-4f21-a41b-961a662bb228"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        }
      ]
    }
  ]
}