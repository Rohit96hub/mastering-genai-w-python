{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**HR-Assistant**\n",
        "- Apply dataset as \"docs\" to the LLM\n",
        "- User asks questions about Employess from the dataset"
      ],
      "metadata": {
        "id": "3KCIPLH8Sunk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Example 1: HR Chatbot**"
      ],
      "metadata": {
        "id": "UbCuxG1AZHiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Import statements**\n"
      ],
      "metadata": {
        "id": "-e4ps4A6XQKs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7fab282-a26e-4e88-af33-c85365fd5287"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7ba882d-212f-4ddf-b5c6-f7c85a15e16b"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bebd30f0-3e85-4b09-b176-0b72fb988dae"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54a08d5f-dcfc-44d8-affc-65f3130cbdbd"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Function to read the Dataset**"
      ],
      "metadata": {
        "id": "3wCw8IYqXf6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "685c03c1-e0c9-4e6a-aae4-2f105254c717"
      },
      "outputs": [],
      "source": [
        "directory=\"hrdataset/employees\"\n",
        "def read_markdown_files(directory):\n",
        "    \"\"\"Read and load content from all Markdown files in a directory.\"\"\"\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".md\"):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                documents.append({\"filename\": filename, \"content\": f.read()})\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c29ef45-057a-4af1-a7fc-c350b62a8c8c"
      },
      "outputs": [],
      "source": [
        "docs=read_markdown_files(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Build User Message**"
      ],
      "metadata": {
        "id": "mQuLiGhJXyKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8837da7-411b-4fb2-8818-849a6fe49305"
      },
      "outputs": [],
      "source": [
        "def build_user_messages(question):\n",
        "    message = \"\"\n",
        "    message += f\"Here is info about all the employees {docs}\"\n",
        "    message += f\"now answer query {question}\"\n",
        "    return message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47f18047-3f38-4fde-9b92-e3c007db3369"
      },
      "outputs": [],
      "source": [
        "system_message=\"You are a helpful HR assistant\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Function to Generate LLM Response**"
      ],
      "metadata": {
        "id": "fV7szo2UX5Fw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "001b95b2-4cc5-4cc1-953e-29bc176404f2"
      },
      "outputs": [],
      "source": [
        "def process_question_gpt(message, history):\n",
        "    prompt = build_user_messages(message)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=messages,\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Gradio ChatInterface**"
      ],
      "metadata": {
        "id": "SpBQ_4xHYNi2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1defa62-46a2-4be0-b9e4-846da9c23979",
        "outputId": "e620ef29-ef75-4379-ddc9-543bbd34e22f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/genai/lib/python3.11/site-packages/gradio/chat_interface.py:317: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "demo = gr.ChatInterface(\n",
        "    process_question_gpt,\n",
        "    chatbot=gr.Chatbot(\n",
        "        height=450,\n",
        "        placeholder=\"Ask the question about Employees\",\n",
        "        type=\"messages\",  # Proper rendering of chat format\n",
        "    ),\n",
        "    textbox=gr.Textbox(\n",
        "        placeholder=\"What do you want to know about your co-workers?\",\n",
        "        container=False,\n",
        "        scale=7,\n",
        "    ),\n",
        "    title=\"Know your co-workers?\",\n",
        "    examples=[\"Who is the CEO of the company?\", \"who joined the company recently\"],\n",
        "    cache_examples=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f8e6673-f50e-4aae-bbde-63e29574e379",
        "outputId": "ceae64dc-ff74-4a4f-e98a-327a1c6b8d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7925\n",
            "* Running on public URL: https://91f5a00c9b5a4c160d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://91f5a00c9b5a4c160d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1247b751-3f60-48f2-93af-d27d1e4ede7a"
      },
      "source": [
        "##**Example 2 - Gradio ChatInterface With Memory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d9806ca-e46f-456a-bf4c-1de9eec672dd"
      },
      "outputs": [],
      "source": [
        "def build_messages_with_history(question, history):\n",
        "    prompt = \"\"\n",
        "\n",
        "    messages = []\n",
        "    for entry in history:\n",
        "        if entry[\"role\"] == \"user\":\n",
        "            messages.append({\"role\": \"user\", \"content\": entry[\"content\"]})\n",
        "        elif entry[\"role\"] == \"assistant\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": entry[\"content\"]})\n",
        "\n",
        "    prompt += f\"Here is info about all the employees {docs}\"\n",
        "    prompt += f\"{messages}\"\n",
        "    prompt += f\"now answer query {question}\"\n",
        "\n",
        "    #print(prompt)\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67357276-02a1-4e59-85f8-d46ff8ede3bf"
      },
      "outputs": [],
      "source": [
        "def process_question_gpt_with_history(message, history):\n",
        "\n",
        "    prompt = build_messages_with_history(message, history)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=messages,\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2407ce9-2eca-45ef-97cf-01df017569e3",
        "outputId": "16a956a6-d5c4-44b5-f58c-316c94241d2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/genai/lib/python3.11/site-packages/gradio/chat_interface.py:317: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "demo2 = gr.ChatInterface(\n",
        "    process_question_gpt_with_history,\n",
        "    chatbot=gr.Chatbot(\n",
        "        height=450,\n",
        "        placeholder=\"Ask the question about Employees\",\n",
        "        type=\"messages\",  # Proper rendering of chat format\n",
        "    ),\n",
        "    textbox=gr.Textbox(\n",
        "        placeholder=\"What do you want to know about your co-workers?\",\n",
        "        container=False,\n",
        "        scale=7,\n",
        "    ),\n",
        "    title=\"Know your co-workers?\",\n",
        "    examples=[\"Who is the CEO of the company?\", \"who joined the company recently\"],\n",
        "    cache_examples=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f505466f-2615-4298-a590-c83bc5280035",
        "outputId": "002b2cb4-f78d-4a66-8367-3047be8e42d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "* Running on public URL: https://c1dd51b9bfd67a460e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://c1dd51b9bfd67a460e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo2.launch(share=True)"
      ]
    }
  ]
}