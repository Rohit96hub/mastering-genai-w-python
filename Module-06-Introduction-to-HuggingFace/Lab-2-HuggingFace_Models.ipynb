{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ffzH6kbNyTVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec0ec99-bc28-4443-9f56-e17d00b7fd3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-3.1.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading patool-3.1.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import patoolib"
      ],
      "metadata": {
        "id": "0E7edasT0Luf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZnUG1PV13PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patoolib.extract_archive(\"hrdataset.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "di-DdcGH0Qiv",
        "outputId": "f04a34dc-d987-4d2d-b6cc-1f85a9e6a2bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting hrdataset.zip ...\n",
            "INFO:patool:Extracting hrdataset.zip ...\n",
            "INFO patool: running /usr/bin/7z x -aou -o./Unpack_kvdr5uux -- hrdataset.zip\n",
            "INFO:patool:running /usr/bin/7z x -aou -o./Unpack_kvdr5uux -- hrdataset.zip\n",
            "INFO patool: ... hrdataset.zip extracted to `hrdataset'.\n",
            "INFO:patool:... hrdataset.zip extracted to `hrdataset'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hrdataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/hrdataset/employees"
      ],
      "metadata": {
        "id": "CPowWkmG0bQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing markdown files\n",
        "markdown_dir = \"/content/hrdataset/employees\"\n",
        "\n",
        "# Parse markdown files into a DataFrame\n",
        "employee_data = []\n",
        "for filename in os.listdir(markdown_dir):\n",
        "    if filename.endswith(\".md\"):\n",
        "        with open(os.path.join(markdown_dir, filename), \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            profile = {}\n",
        "            for line in lines:\n",
        "                if line.startswith(\"- **Name:**\"):\n",
        "                    profile[\"Name\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "                elif line.startswith(\"- **Role:**\"):\n",
        "                    profile[\"Role\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "                elif line.startswith(\"- **Department:**\"):\n",
        "                    profile[\"Department\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "                elif line.startswith(\"- **Joining Date:**\"):\n",
        "                    profile[\"Joining Date\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "            if profile:\n",
        "                employee_data.append(profile)\n",
        "\n",
        "# Convert to DataFrame\n",
        "employee_df = pd.DataFrame(employee_data)\n",
        "print(employee_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px06wCYB1ShG",
        "outputId": "9aaa166b-0f0d-458b-a246-475f9e3c3b37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Name                Role       Department Joining Date\n",
            "0     Sunita Patil   Finance Executive          Finance   2022-01-17\n",
            "1    Neha Malhotra      Junior Analyst        Logistics   2023-07-01\n",
            "2       Anjali Das        HR Executive  Human Resources   2021-05-10\n",
            "3       Amit Verma                 CEO        Executive   2016-02-01\n",
            "4      Aditya Jain    Senior Developer               IT   2019-06-10\n",
            "5      Rohit Mehra   Logistics Analyst        Logistics   2020-08-22\n",
            "6  Rajesh Kulkarni                 CTO        Executive   2017-11-15\n",
            "7     Priya Sharma  Operations Manager       Operations   2019-03-15\n",
            "8     Karan Kapoor    Fleet Supervisor        Logistics   2018-11-03\n",
            "9       Meera Iyer   Marketing Manager        Marketing   2020-02-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqN0AjtpEsaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization Models\n",
        "These models are pre-trained for text summarization tasks.\n",
        "\n",
        "* facebook/bart-large-cnn: The go-to model for\n",
        "summarization, trained on large news datasets.\n",
        "\n",
        "* t5-small, t5-base, t5-large: Highly versatile models that can perform summarization and many other tasks.\n",
        "  **Usage:** Prefix input with \"summarize: \".\n",
        "\n",
        "* pegasus-xsum (Google Research): Specialized in abstractive summarization.\n",
        "* google/long-t5-tglobal-base: Designed for summarizing longer documents effectively."
      ],
      "metadata": {
        "id": "Riu6Ve9MFyK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Combine employee details for a specific department\n",
        "operations_data = \" \".join([\n",
        "    f\"{row['Name']} is the {row['Role']} in {row['Department']}, joined on {row['Joining Date']}.\"\n",
        "    for _, row in employee_df.iterrows() if row['Department'] == \"Executive\"\n",
        "])\n",
        "\n",
        "# Summarize the data\n",
        "summary = summarizer(operations_data, max_length=50,min_length=10, do_sample=False)\n",
        "print(\"Summary:\", summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCBXyenw1U-V",
        "outputId": "b2289d45-5410-450a-e1a8-b009f4bb5f6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Your max_length is set to 50, but your input_length is only 40. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Amit Verma is the CEO in Executive. Rajesh Kulkarni is the CTO in Executive, joined on 2017-11-15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering Models\n",
        "These models are trained to answer questions based on a provided context.\n",
        "\n",
        "* distilbert-base-uncased-distilled-squad: A lightweight QA model based on the SQuAD dataset.\n",
        "\n",
        "* bert-large-uncased-whole-word-masking-finetuned-squad: A more powerful BERT-based QA model.\n",
        "\n",
        "* deepset/roberta-base-squad2: Trained on SQuAD2.0, supports unanswerable questions."
      ],
      "metadata": {
        "id": "u3ebtrs5GpbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "# context = \"Priya Sharma is the Operations Manager who joined the company in 2019.\"\n",
        "context = summary[0]['summary_text']\n",
        "question = \"Who is the CEO?\"\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prKMgSUk3NRS",
        "outputId": "b75a7ffe-47bf-48e3-8858-9ed40cdb7015"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.9947599172592163, 'start': 0, 'end': 10, 'answer': 'Amit Verma'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification Models\n",
        "For sentiment analysis, topic classification, and other classification tasks.\n",
        "\n",
        "* distilbert-base-uncased-finetuned-sst-2-english: Sentiment analysis model.\n",
        "* cardiffnlp/twitter-roberta-base-sentiment: Specifically designed for sentiment analysis on tweets.\n",
        "* facebook/bart-large-mnli: Can be used for zero-shot text classification."
      ],
      "metadata": {
        "id": "ynHtwkHFHBh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "result = classifier(\"The employee feedback has been overwhelmingly positive!\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "OYSpQbauGcat",
        "outputId": "cde6bb17-1b82-4469-e842-2092906f0d17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f386022a2364144821788b74066461c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bba361104ff4af08cd5771fde68dce4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8431507c28b47bea708642c1c8ffb30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0f9ecc5f6d041bda6b799ca42c23f49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9997122883796692}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Models\n",
        "For similarity search, clustering, and other embedding-based tasks.\n",
        "\n",
        "* sentence-transformers/all-MiniLM-L6-v2: A lightweight embedding model for generating sentence embeddings.\n",
        "* openai/clip-vit-base-patch32: Generates embeddings for both text and images.\n",
        "* bert-base-uncased: You can extract hidden states to use as embeddings."
      ],
      "metadata": {
        "id": "CAuQEC6uHWbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model.encode([\"This is a test sentence.\", \"Another example.\"])\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "0VY_qaWAHKiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation Models\n",
        "For generating text, completing sentences, or creating creative outputs.\n",
        "\n",
        "* gpt2, distilgpt2: Lightweight generative models for text generation.\n",
        "* EleutherAI/gpt-neo-2.7B: A larger open-source alternative to GPT-3.\n",
        "* bigscience/bloom: A multilingual generative model.\n",
        "* facebook/opt-13b: Efficient, open-source large language model."
      ],
      "metadata": {
        "id": "F4GY07sLHpm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "text = generator(\"Once upon a time, there was a curious employee who\", max_length=50)\n",
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
         },
        "id": "bUKq6n0kHf74",
        "outputId": "50d9370c-0ca2-4b1a-8877-e9ce7a4dea13"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab01f5c3cb18442b8e7ed3d99923c6d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c358d145b516471aab29a30225324e0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c2385a752d46d9bf2226d67b80d8ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e6d17d1cc2e4e93a8a90489a3616bce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4755f98e4f7c44e0ab615339c2d867d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e32fe900372641e8b1880eac362bdde5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc49adbe38d64ce7a1f95265920a1c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a curious employee who wished to share this news with his friends and acquaintances. He made sure his name was only acknowledged to every living person in this town where he attended college to which he had not paid taxes and no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition (NER) Models\n",
        "For extracting entities like names, dates, organizations, etc., from text.\n",
        "\n",
        "* dbmdz/bert-large-cased-finetuned-conll03-english: Fine-tuned on CoNLL-2003 for NER.\n",
        "* dslim/bert-base-NER: Lightweight NER model"
      ],
      "metadata": {
        "id": "tVtHVa7oIMGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
        "text = \"Neependra Khare founded CloudYuga in December 2015\"\n",
        "entities = ner(text)\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsbvTOn5ICip",
        "outputId": "54c1baa1-3d42-4345-eabf-1f4af6ef2294"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'PER', 'score': 0.9995653, 'word': 'Neependra Khare', 'start': 0, 'end': 15}, {'entity_group': 'ORG', 'score': 0.97774523, 'word': 'CloudYuga', 'start': 24, 'end': 33}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation Models\n",
        "For translating text between languages.\n",
        "\n",
        "- Helsinki-NLP/opus-mt-en-de: English-to-German translation.\n",
        "- t5-small, t5-large: Can also be used for translation by prefixing the input with translate English to French:."
      ],
      "metadata": {
        "id": "rdGf1lf1JRTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "translation = translator(\"The employee feedback has been overwhelmingly positive!\")\n",
        "print(translation[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "qDIYwyZsIWpS",
        "outputId": "bae6c954-b302-4afb-e329-992adedf27c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "191c7b7e15a24c739f13b17756e57ab8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ad116fd6a714e9b966e75246cef9f33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40df90adea2840efa9cf2331a8c3e7a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dc7656ebcc949f78588c6ac259bf0b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3459d7fda1947279f0472ae5ba85669"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc2443b376dc4216a3c87fb0409e1c69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ead97ca3452d4067bfd16b32c5f3f434"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das Feedback der Mitarbeiter war überwältigend positiv!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tl407MfpJcPI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}