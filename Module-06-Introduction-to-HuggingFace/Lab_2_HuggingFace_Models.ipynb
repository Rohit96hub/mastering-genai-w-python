{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**HuggingFace Models**\n",
        "In this notebook, we will cover the following models from Huggingface.\n",
        "\n",
        "1. Summarization Models\n",
        "2. Question Answering Models\n",
        "3. Text Classification Models\n",
        "4. Embedding Models\n",
        "5. Text Generation Models\n",
        "6. Named Entity Recognition (NER) Models\n",
        "7. Translation Models\n",
        "\n",
        "If you want to explore more models please refer\n",
        "https://huggingface.co/models"
      ],
      "metadata": {
        "id": "jaelW04SHoxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Install Dependencies**"
      ],
      "metadata": {
        "id": "9lxwJZXcNkHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHYgvd2NrZo",
        "outputId": "746c8905-900b-4a9d-b3da-bf94c270e068"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.13.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Downloads the `hrdataset.zip` file from the CloudYuga GitHub repo**\n",
        "\n",
        "Saves it in the current working directory of notebook\n",
        "\n",
        "(e.g., /content/ in Google Colab)."
      ],
      "metadata": {
        "id": "MOpZaD36G3Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudyuga/mastering-genai-w-python/raw/refs/heads/main/hrdataset.zip"
      ],
      "metadata": {
        "id": "hN-NCqEQG8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e84d56-717b-440a-b4dc-b65540918956"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-26 06:20:19--  https://github.com/cloudyuga/mastering-genai-w-python/raw/refs/heads/main/hrdataset.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/cloudyuga/mastering-genai-w-python/refs/heads/main/hrdataset.zip [following]\n",
            "--2025-05-26 06:20:19--  https://raw.githubusercontent.com/cloudyuga/mastering-genai-w-python/refs/heads/main/hrdataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9530 (9.3K) [application/zip]\n",
            "Saving to: ‘hrdataset.zip.1’\n",
            "\n",
            "hrdataset.zip.1     100%[===================>]   9.31K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-26 06:20:20 (12.4 MB/s) - ‘hrdataset.zip.1’ saved [9530/9530]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Unzip `hrdataset.zip` file**\n",
        "- It will automatically create **`hrdataset`** folder in our current working directory (/content/ in Google Colab)"
      ],
      "metadata": {
        "id": "m4EbECM8G72L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip hrdataset.zip"
      ],
      "metadata": {
        "id": "5alH8nd6HLhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0058780-295f-43af-8eaa-d5446d51585c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  hrdataset.zip\n",
            "replace hrdataset/policies/leave_policies.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/policies/training_and_development.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/policies/employee_benefits.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/policies/holiday_calendar.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/policies/events_calendar.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/surveys/Employee_Culture_Survey_Responses.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/108_Rajesh_Kulkarni.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/106_Neha_Malhotra.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/103_Anjali_Das.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/105_Sunita_Patil.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/101_Priya_Sharma.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/102_Rohit_Mehra.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/104_Karan_Kapoor.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/109_Meera_Iyer.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/110_Aditya_Jain.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/107_Amit_Verma.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hrdataset/employees/payroll_information.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/hrdataset/employees\n"
      ],
      "metadata": {
        "id": "CPowWkmG0bQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f74e0cb-b602-4168-c0a6-935112efa12d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101_Priya_Sharma.md  105_Sunita_Patil.md     109_Meera_Iyer.md\n",
            "102_Rohit_Mehra.md   106_Neha_Malhotra.md    110_Aditya_Jain.md\n",
            "103_Anjali_Das.md    107_Amit_Verma.md\t     payroll_information.md\n",
            "104_Karan_Kapoor.md  108_Rajesh_Kulkarni.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing markdown files\n",
        "markdown_dir = \"/content/hrdataset/employees\"\n",
        "\n",
        "# Parse markdown files into a DataFrame\n",
        "employee_data = []\n",
        "for filename in os.listdir(markdown_dir):\n",
        "    if filename.endswith(\".md\"):\n",
        "        with open(os.path.join(markdown_dir, filename), \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            profile = {}\n",
        "            for line in lines:\n",
        "                if line.startswith(\"- **Name:**\"):\n",
        "                    profile[\"Name\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "                elif line.startswith(\"- **Role:**\"):\n",
        "                    profile[\"Role\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "                elif line.startswith(\"- **Department:**\"):\n",
        "                    profile[\"Department\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "                elif line.startswith(\"- **Joining Date:**\"):\n",
        "                    profile[\"Joining Date\"] = line.split(\":\")[1].strip(\"**\").strip(\"\\n\").strip(\" \")\n",
        "            if profile:\n",
        "                employee_data.append(profile)\n",
        "\n",
        "# Convert to DataFrame\n",
        "employee_df = pd.DataFrame(employee_data)\n",
        "print(employee_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px06wCYB1ShG",
        "outputId": "3bc989ac-5410-4f83-a9eb-fb695685ef78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Name                Role       Department Joining Date\n",
            "0  Rajesh Kulkarni                 CTO        Executive   2017-11-15\n",
            "1       Amit Verma                 CEO        Executive   2016-02-01\n",
            "2       Meera Iyer   Marketing Manager        Marketing   2020-02-20\n",
            "3      Aditya Jain    Senior Developer               IT   2019-06-10\n",
            "4      Rohit Mehra   Logistics Analyst        Logistics   2020-08-22\n",
            "5       Anjali Das        HR Executive  Human Resources   2021-05-10\n",
            "6    Neha Malhotra      Junior Analyst        Logistics   2023-07-01\n",
            "7     Karan Kapoor    Fleet Supervisor        Logistics   2018-11-03\n",
            "8     Priya Sharma  Operations Manager       Operations   2019-03-15\n",
            "9     Sunita Patil   Finance Executive          Finance   2022-01-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Summarization Models**\n",
        "These models are pre-trained for text summarization tasks.\n",
        "\n",
        "* facebook/bart-large-cnn: The go-to model for\n",
        "summarization, trained on large news datasets.\n",
        "\n",
        "* t5-small, t5-base, t5-large: Highly versatile models that can perform summarization and many other tasks.\n",
        "  **Usage:** Prefix input with \"summarize: \".\n",
        "\n",
        "* pegasus-xsum (Google Research): Specialized in abstractive summarization.\n",
        "* google/long-t5-tglobal-base: Designed for summarizing longer documents effectively."
      ],
      "metadata": {
        "id": "Riu6Ve9MFyK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Combine employee details for a specific department\n",
        "operations_data = \" \".join([\n",
        "    f\"{row['Name']} is the {row['Role']} in {row['Department']}, joined on {row['Joining Date']}.\"\n",
        "    for _, row in employee_df.iterrows() if row['Department'] == \"Executive\"\n",
        "])\n",
        "\n",
        "# Summarize the data\n",
        "summary = summarizer(operations_data, max_length=50,min_length=10, do_sample=False)\n",
        "print(\"Summary:\", summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCBXyenw1U-V",
        "outputId": "e144a31c-3a73-488f-b1c2-cea78754f7d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "Your max_length is set to 50, but your input_length is only 40. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Rajesh Kulkarni is the CTO in Executive. Amit Verma is the CEO in Executive, joined on 2016-02-01.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Question Answering Models**\n",
        "These models are trained to answer questions based on a provided context.\n",
        "\n",
        "* distilbert-base-uncased-distilled-squad: A lightweight QA model based on the SQuAD dataset.\n",
        "\n",
        "* bert-large-uncased-whole-word-masking-finetuned-squad: A more powerful BERT-based QA model.\n",
        "\n",
        "* deepset/roberta-base-squad2: Trained on SQuAD2.0, supports unanswerable questions."
      ],
      "metadata": {
        "id": "u3ebtrs5GpbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "# context = \"Priya Sharma is the Operations Manager who joined the company in 2019.\"\n",
        "context = summary[0]['summary_text']\n",
        "question = \"Who is the CEO?\"\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prKMgSUk3NRS",
        "outputId": "fa0c2328-2208-4da8-9784-3c759d0b1afb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.9975013732910156, 'start': 41, 'end': 51, 'answer': 'Amit Verma'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Text Classification Models**\n",
        "For sentiment analysis, topic classification, and other classification tasks.\n",
        "\n",
        "* distilbert-base-uncased-finetuned-sst-2-english: Sentiment analysis model.\n",
        "* cardiffnlp/twitter-roberta-base-sentiment: Specifically designed for sentiment analysis on tweets.\n",
        "* facebook/bart-large-mnli: Can be used for zero-shot text classification."
      ],
      "metadata": {
        "id": "ynHtwkHFHBh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "result = classifier(\"The employee feedback has been overwhelmingly positive!\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYSpQbauGcat",
        "outputId": "e12052c8-3c28-4d17-972e-71ceb7827709"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9997122883796692}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. Embedding Models**\n",
        "For similarity search, clustering, and other embedding-based tasks.\n",
        "\n",
        "* sentence-transformers/all-MiniLM-L6-v2: A lightweight embedding model for generating sentence embeddings.\n",
        "* openai/clip-vit-base-patch32: Generates embeddings for both text and images.\n",
        "* bert-base-uncased: You can extract hidden states to use as embeddings."
      ],
      "metadata": {
        "id": "CAuQEC6uHWbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model.encode([\"This is a test sentence.\", \"Another example.\"])\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "0VY_qaWAHKiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c54eb1-a433-4014-ef7a-5b19ea843abd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.42964798e-02  5.79537116e-02  4.49332502e-03  1.05821133e-01\n",
            "   7.08347186e-03 -1.78446826e-02 -1.68880690e-02 -1.52283777e-02\n",
            "   4.04731482e-02  3.34225185e-02  1.04327612e-01 -4.70358692e-02\n",
            "   6.88471459e-03  4.10179794e-02  1.87119059e-02 -4.14923131e-02\n",
            "   2.36474667e-02 -5.65018319e-02 -3.36961895e-02  5.09910360e-02\n",
            "   6.93032816e-02  5.47842421e-02 -9.78836883e-03  2.36971844e-02\n",
            "   1.99965108e-02  9.71729215e-03 -5.88991717e-02  7.30747916e-03\n",
            "   4.70264405e-02 -4.51009814e-03 -5.57996780e-02 -4.15945984e-03\n",
            "   6.47570491e-02  4.80762906e-02  1.70207825e-02 -3.18336999e-03\n",
            "   5.74024208e-02  3.52318995e-02 -5.88387111e-03  1.48328794e-02\n",
            "   1.15763210e-02 -1.07480787e-01  1.91041604e-02  2.20857337e-02\n",
            "   1.08645940e-02  3.78195709e-03 -3.19403596e-02  1.07277585e-02\n",
            "  -4.84234374e-03 -2.83362307e-02 -5.25735430e-02 -7.05868527e-02\n",
            "  -5.75557537e-02 -1.36328777e-02  5.68219274e-03  2.30746306e-02\n",
            "   3.56978178e-02  1.49984220e-02  4.97427844e-02  4.26283479e-02\n",
            "  -3.45888846e-02 -2.43600160e-02 -7.15223849e-02  8.31247196e-02\n",
            "   1.48918971e-01  5.40180318e-02 -4.13382314e-02 -8.98984969e-02\n",
            "  -4.45253067e-02  1.47391791e-02  2.23118961e-02  1.95736103e-02\n",
            "   4.36339863e-02  9.81223397e-03 -3.80728906e-03 -1.49928499e-02\n",
            "  -6.99192169e-04 -1.12847432e-01  1.23841859e-01  5.55581227e-02\n",
            "  -8.89102146e-02 -7.88501203e-02 -1.68932825e-02  4.59775440e-02\n",
            "  -8.72698799e-03 -5.81384376e-02  7.65900388e-02 -3.43224518e-02\n",
            "  -7.92424902e-02  2.17661541e-02 -3.42496186e-02 -2.64467523e-02\n",
            "   5.29812882e-03  4.52738767e-03 -5.10180555e-02 -1.65862683e-02\n",
            "  -8.30451697e-02 -2.37127510e-03 -1.11335015e-03  4.30594012e-02\n",
            "   4.37790435e-03  2.54991055e-02  7.46883918e-03  6.31696582e-02\n",
            "  -9.80584323e-02 -8.79312083e-02  3.53147014e-04 -5.76699153e-02\n",
            "   2.06372943e-02 -7.73531711e-03 -3.06464583e-02 -2.09900271e-03\n",
            "   5.95591217e-02  1.95797030e-02 -1.24724917e-02  9.70808230e-03\n",
            "  -1.23177424e-01  2.59908754e-02 -1.57766696e-02  4.94351164e-02\n",
            "   6.15411513e-02  7.83011988e-02 -2.96914522e-02 -1.31864967e-02\n",
            "  -6.23510256e-02 -8.06827098e-02  5.49654178e-02 -6.96259116e-33\n",
            "  -2.58421041e-02 -6.67799041e-02  4.35139015e-02  7.39991963e-02\n",
            "   1.02593126e-02 -2.44536307e-02 -2.12487951e-02  6.83941990e-02\n",
            "  -2.29249056e-02 -7.92041901e-05 -2.58224690e-03 -9.48837325e-02\n",
            "   1.33109139e-02  4.06304672e-02  8.56217667e-02  9.81819481e-02\n",
            "  -7.66808242e-02  6.95324093e-02 -4.67463061e-02  5.55346012e-02\n",
            "  -3.53191793e-02  3.81224193e-02 -1.84668023e-02 -6.54691607e-02\n",
            "  -9.12842676e-02 -1.11914895e-01  2.20798864e-03  8.41347314e-03\n",
            "  -4.70665433e-02  2.03569364e-02  1.06555726e-02  2.61043161e-02\n",
            "  -2.67808698e-02  6.01193570e-02  2.02774853e-02  1.66951716e-02\n",
            "   3.52879278e-02 -7.81728700e-02 -2.58370601e-02  1.02496417e-02\n",
            "  -6.14753254e-02 -2.84758378e-02 -1.02758398e-02  1.26739107e-02\n",
            "   9.54696760e-02 -1.21438606e-02 -1.42458212e-02 -2.61924285e-02\n",
            "  -6.29929639e-03  2.21966878e-02 -2.60840096e-02  4.39434201e-02\n",
            "   7.36454129e-02 -3.33893672e-02  3.21776196e-02  6.46691993e-02\n",
            "   4.93193939e-02 -1.05321072e-02 -3.47278751e-02  6.57102168e-02\n",
            "  -2.72232257e-02  6.03555813e-02 -6.00290149e-02  5.62708564e-02\n",
            "   6.80892449e-03  1.87106784e-02 -4.29099426e-02 -4.09596749e-02\n",
            "   5.29919490e-02  3.30944173e-02 -1.55465808e-02 -7.29866996e-02\n",
            "  -5.08884117e-02  6.31101653e-02 -1.29772956e-02 -7.07978159e-02\n",
            "   1.48705672e-02  3.42567712e-02  8.29499960e-03  9.79077164e-03\n",
            "   2.34169513e-02 -1.12109460e-01  2.82359142e-02 -5.27849346e-02\n",
            "  -9.38261375e-02 -5.61817200e-04 -1.93163436e-02 -8.85619000e-02\n",
            "   2.44563036e-02 -2.48154346e-02  1.29733067e-02  2.32092012e-02\n",
            "   3.92325893e-02 -3.37320492e-02  2.21172627e-02  2.89706332e-33\n",
            "  -3.42555009e-02  6.55489936e-02 -7.17757121e-02  8.65405127e-02\n",
            "   8.71615484e-02 -3.01420577e-02  6.58367202e-02 -3.34099233e-02\n",
            "  -3.74904722e-02  1.34898037e-01 -4.51038666e-02  3.30192372e-02\n",
            "  -4.24039224e-03 -2.20894851e-02  3.93681824e-02  1.12860957e-02\n",
            "   1.08165070e-02 -4.90267761e-02 -1.82854943e-02 -2.39171460e-02\n",
            "  -5.86305484e-02  1.26434639e-01  1.70784481e-02  1.01735651e-01\n",
            "  -4.16656956e-02  3.73764802e-03  1.43010169e-02 -6.77730888e-02\n",
            "  -7.40957409e-02  2.02464927e-02  2.11449526e-02 -3.38305756e-02\n",
            "  -9.98556167e-02 -8.47221073e-03  1.07290307e-02  8.69128481e-03\n",
            "   1.02407850e-01 -7.64335394e-02 -5.17601110e-02  3.09731420e-02\n",
            "   4.11773287e-03  2.74708867e-02  6.67324439e-02  1.43499017e-01\n",
            "   1.36023471e-02  1.20409923e-02 -2.44526044e-02 -1.40914813e-01\n",
            "  -4.33224291e-02  4.30766158e-02 -5.55888303e-02  2.39927787e-02\n",
            "  -1.26895560e-02  1.73371229e-02 -6.77698404e-02  1.13578988e-02\n",
            "  -3.18791941e-02 -2.96404939e-02 -2.50596721e-02 -2.26741936e-03\n",
            "  -9.76275504e-02  6.03500940e-02  6.84160693e-03  3.21439654e-02\n",
            "   2.29486972e-02 -7.13614374e-02 -7.71940351e-02  9.53402370e-02\n",
            "   2.65478566e-02 -6.03252575e-02  1.02911055e-01  2.95908395e-02\n",
            "  -1.08882353e-01 -2.48065181e-02 -3.32333446e-02 -8.23532566e-02\n",
            "  -8.17733109e-02 -1.76423192e-02 -1.93137173e-02 -8.29819813e-02\n",
            "  -1.80561133e-02 -5.32800145e-02  4.69954824e-03  1.52580524e-02\n",
            "  -8.14496875e-02  3.85303870e-02 -4.42598714e-03 -2.79708859e-02\n",
            "  -1.02035869e-02  4.41999845e-02 -1.69339310e-02 -5.51321618e-02\n",
            "   3.97406034e-02 -2.30482873e-02 -2.68449131e-02 -1.95805310e-08\n",
            "  -1.86720174e-02 -1.17110070e-02  1.46480277e-02  6.65860856e-03\n",
            "   7.37097464e-04  6.25822395e-02  6.77657649e-02 -5.95500367e-03\n",
            "  -3.05196233e-02 -8.19972076e-04  6.42959028e-02  6.64169937e-02\n",
            "  -9.79511142e-02 -8.53809161e-06  6.03237525e-02 -2.74022389e-02\n",
            "   2.42515337e-02 -2.12565027e-02 -2.66954582e-03  8.42972547e-02\n",
            "  -4.84722145e-02  4.77524698e-02  1.31909540e-02  4.64869626e-02\n",
            "  -2.97928206e-03  4.41555679e-02  9.95891467e-02  6.42727911e-02\n",
            "   3.36076762e-03  4.49756496e-02  1.10251836e-01  6.42667711e-02\n",
            "  -3.68151404e-02 -3.15478966e-02 -1.47667006e-02  8.22646394e-02\n",
            "   5.67149855e-02 -6.49479851e-02  2.30806191e-02  1.92347635e-02\n",
            "  -5.15443310e-02  7.22280070e-02 -1.43920854e-02  7.81815872e-02\n",
            "  -1.11626666e-02 -4.95682620e-02 -3.15908529e-02 -2.95475069e-02\n",
            "  -1.51651548e-02 -5.39254881e-02 -8.85926094e-03  2.10648682e-02\n",
            "   4.50276323e-02 -2.28812173e-02  2.68128570e-02 -3.30655091e-02\n",
            "  -3.49510531e-03 -3.04148942e-02 -7.15666637e-02  2.32957415e-02\n",
            "   8.97689313e-02  4.57106810e-03  8.18802789e-02 -9.90470946e-02]\n",
            " [ 3.53473388e-02 -1.12804091e-02 -3.11247632e-03  5.96170351e-02\n",
            "  -8.58743582e-03 -1.65632609e-02  4.28851806e-02 -3.32065597e-02\n",
            "  -7.89202936e-03 -1.38152232e-02  4.87344339e-02  3.81426029e-02\n",
            "   7.20615312e-02  4.09856550e-02  6.52014930e-03 -2.35958069e-04\n",
            "   3.76207195e-02 -5.23421951e-02 -6.77950233e-02  2.00104415e-02\n",
            "   1.24545498e-02 -2.97476090e-02  2.78888028e-02  3.96238081e-02\n",
            "  -1.71502046e-02 -1.04651079e-01 -5.56862541e-02  1.06797978e-01\n",
            "   9.69130844e-02 -1.52073279e-02  1.80520769e-02 -1.92706306e-02\n",
            "  -3.02628428e-02  3.07972077e-03  2.32448727e-02  1.03380077e-01\n",
            "  -2.10984685e-02  1.03165403e-01 -8.41627270e-02 -2.12200228e-02\n",
            "  -3.19848838e-03 -1.98301277e-03 -1.66169088e-03 -4.41353442e-03\n",
            "  -2.63725705e-02 -9.29467902e-02  2.69680768e-02  3.14101838e-02\n",
            "  -1.27220037e-03 -1.01681851e-01 -4.79180589e-02  4.49322537e-02\n",
            "  -7.81437457e-02  2.25009266e-02  1.95821840e-02 -1.95779875e-02\n",
            "  -2.65876614e-02  4.14857268e-02  1.05970912e-02  7.68778787e-04\n",
            "   1.47975348e-02  3.11092311e-03 -9.93989706e-02  6.02653362e-02\n",
            "   5.78659698e-02 -7.59362895e-03  2.60993205e-02  9.77611169e-02\n",
            "  -1.15128987e-01  8.35282207e-02  8.23395699e-02  2.62941997e-02\n",
            "  -3.91551107e-02  5.34089878e-02 -3.27382199e-02 -1.51718315e-02\n",
            "   3.37905586e-02  4.80686985e-02 -6.47029048e-03 -2.76267678e-02\n",
            "  -1.08513996e-01 -5.38914502e-02 -2.75378791e-03  7.25232810e-03\n",
            "   5.22085689e-02  4.34427708e-02 -9.49133746e-03 -5.46878055e-02\n",
            "   8.12268108e-02  5.87685257e-02 -9.00800824e-02 -4.83703688e-02\n",
            "   3.09251398e-02 -4.03093211e-02  1.07682729e-02 -2.46718563e-02\n",
            "   3.00520267e-02 -5.18294685e-02 -7.80044273e-02  1.46775573e-01\n",
            "  -4.13824394e-02  1.03432350e-01  1.86913311e-02  3.82358544e-02\n",
            "  -3.47926747e-03 -6.25510439e-02 -6.03499029e-05 -5.10627031e-02\n",
            "  -9.40272212e-03 -4.73158509e-02 -7.90592134e-02  2.25619618e-02\n",
            "  -6.16062284e-02 -1.15971006e-02  3.13660391e-02 -6.83015734e-02\n",
            "  -1.48887429e-02  1.28583563e-02 -5.08174673e-02  3.09013911e-02\n",
            "   1.38246343e-02  2.65726279e-02 -1.01918638e-01  3.09297703e-02\n",
            "  -7.86110014e-03 -4.03915234e-02  5.28177023e-02 -6.09842979e-33\n",
            "   3.17935385e-02 -1.09639697e-01 -1.01185380e-03  1.06723411e-02\n",
            "   8.39205980e-02 -9.05420408e-02 -4.78473045e-02 -3.64100449e-02\n",
            "   5.49268946e-02  2.33731288e-02  2.49400875e-03  1.52438413e-02\n",
            "   2.55946480e-02 -3.00960783e-02  1.86955687e-02  7.10610226e-02\n",
            "  -7.99813941e-02  1.81383178e-01  1.64601789e-03 -3.11859138e-02\n",
            "   1.79147022e-03  4.98516709e-02 -1.07650170e-02  5.33464737e-02\n",
            "   1.76430549e-02 -3.26845087e-02  7.74100199e-02 -8.66901875e-03\n",
            "   9.60036516e-02  3.39561813e-02 -3.12558860e-02  4.43837903e-02\n",
            "   1.55274365e-02  6.06423467e-02  9.18914378e-02  1.91422198e-02\n",
            "   1.37482081e-02  1.83580369e-02  1.20846229e-02 -1.89149883e-02\n",
            "  -3.71204093e-02 -2.40159016e-02 -1.14327539e-02 -1.94069296e-02\n",
            "   6.62206635e-02 -5.94434850e-02  3.00784111e-02  3.39822322e-02\n",
            "  -7.10559636e-02  1.11186700e-02  2.84247771e-02  5.98871484e-02\n",
            "  -9.10511985e-03 -5.23407608e-02 -3.87656763e-02 -1.07338019e-02\n",
            "   4.95921113e-02  3.25279273e-02  8.02905764e-03  3.43530043e-03\n",
            "  -7.66200870e-02  6.71530366e-02 -3.91053744e-02  4.85275201e-02\n",
            "  -1.16953067e-01  1.36619024e-02 -4.92641237e-03 -5.98329529e-02\n",
            "  -2.86344904e-02  4.77969162e-02  4.36268784e-02  3.02969534e-02\n",
            "  -8.81725550e-02  6.59759622e-04 -6.63668960e-02 -3.60827148e-02\n",
            "  -3.16927582e-02 -6.84882253e-02 -2.23112106e-02 -1.83486417e-02\n",
            "   2.61968318e-02 -1.12088367e-01 -5.94008388e-03  7.30109662e-02\n",
            "   4.50693769e-03  4.24230099e-02  7.65131563e-02 -4.62201275e-02\n",
            "  -4.31480259e-02 -7.12639838e-02 -7.09354207e-02  2.14126334e-02\n",
            "   5.45389690e-02  1.89400986e-02 -6.88370317e-02  4.61592387e-33\n",
            "  -1.04037926e-01  2.58212872e-02 -6.92459792e-02  9.44297761e-02\n",
            "   7.47097656e-02  2.24303268e-02  9.83976424e-02 -5.58496192e-02\n",
            "  -4.22691889e-02  9.68597643e-03 -4.10212539e-02 -2.13917717e-03\n",
            "   5.72874509e-02 -5.65822702e-03 -3.92996101e-03 -7.46640339e-02\n",
            "   5.71114309e-02  2.70252097e-02  9.55032092e-03  2.08064336e-02\n",
            "  -5.61226085e-02  9.61579084e-02 -2.54977085e-02  5.01739159e-02\n",
            "  -4.50793207e-02  6.04049489e-02 -3.93582806e-02  1.53435674e-02\n",
            "  -7.78622106e-02 -2.97783762e-02  1.00762080e-02 -1.70811079e-02\n",
            "  -3.91834937e-02  6.02180185e-03 -7.06148520e-02  8.51103589e-02\n",
            "   4.66131307e-02  2.63533406e-02 -9.28938612e-02 -1.31008653e-02\n",
            "   3.89736407e-02 -1.55651774e-02 -1.56497136e-02  1.38930127e-01\n",
            "  -1.95578430e-02 -2.12597921e-02 -7.80379050e-04 -1.64622776e-02\n",
            "   3.82930189e-02  6.39827028e-02 -1.22056991e-01  2.75910851e-02\n",
            "  -2.74546836e-02 -1.92930512e-02 -5.32623231e-02 -6.30032346e-02\n",
            "  -4.23532240e-02 -8.54471605e-03  2.42689042e-03 -3.70808840e-02\n",
            "  -6.23099646e-03 -5.90473711e-02 -1.85874198e-02  1.02291601e-02\n",
            "   4.98766452e-02 -2.73599308e-02 -7.88872838e-02 -4.25558798e-02\n",
            "   5.34027703e-02  9.29888040e-02  5.86598553e-02 -3.82093340e-02\n",
            "  -5.55658713e-02 -2.11894587e-02 -3.88315469e-02  6.01290651e-02\n",
            "  -2.25036312e-02 -3.33260149e-02 -6.87944964e-02 -5.63534396e-03\n",
            "   3.17302160e-02 -3.59825492e-02 -7.56137865e-03  2.77180206e-02\n",
            "   6.14547357e-02 -2.77356319e-02  1.33490218e-02 -9.21574309e-02\n",
            "  -5.15891612e-02  1.33933742e-02 -1.25200767e-02  7.88262393e-03\n",
            "  -2.77144834e-02  8.23785067e-02  7.13482685e-03 -1.78116171e-08\n",
            "  -5.86621352e-02  4.60780486e-02  1.31773740e-01 -2.08522193e-02\n",
            "   9.41386223e-02 -9.67604015e-03  3.38350050e-02 -1.51667781e-02\n",
            "  -3.15834731e-02 -6.11864626e-02  1.33338245e-02  1.80614199e-02\n",
            "  -3.28497402e-02 -3.09924446e-02  3.25246342e-02  6.11956343e-02\n",
            "   2.13834066e-02 -3.98465432e-03 -4.61930558e-02  1.79252997e-02\n",
            "  -1.00357547e-01  9.91237387e-02 -3.11018862e-02  4.66626743e-03\n",
            "  -9.46831889e-04  1.05921738e-02 -2.18978282e-02  6.26579374e-02\n",
            "   5.92285693e-02 -2.49247290e-02  3.01325824e-02  7.80010819e-02\n",
            "   2.19735727e-02 -4.47724424e-02  8.18961337e-02  3.89879905e-02\n",
            "  -1.31611126e-02 -6.92205178e-03  3.31842266e-02  4.38597761e-02\n",
            "   2.28326786e-02  1.22311348e-02  1.93135312e-03 -1.11773470e-02\n",
            "   9.19877291e-02  8.33102912e-02  7.69861881e-03 -4.97345999e-02\n",
            "   2.59653684e-02  2.40497030e-02 -3.73997204e-02  7.63402581e-02\n",
            "  -8.20020679e-03 -2.54660267e-02  9.44740027e-02  4.00539301e-02\n",
            "   5.89048192e-02  1.72618758e-02 -8.51030275e-02  5.08153513e-02\n",
            "   2.74713952e-02 -2.62777861e-02  5.83148003e-02  4.45819758e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Text Generation Models**\n",
        "For generating text, completing sentences, or creating creative outputs.\n",
        "\n",
        "* gpt2, distilgpt2: Lightweight generative models for text generation.\n",
        "* EleutherAI/gpt-neo-2.7B: A larger open-source alternative to GPT-3.\n",
        "* bigscience/bloom: A multilingual generative model.\n",
        "* facebook/opt-13b: Efficient, open-source large language model."
      ],
      "metadata": {
        "id": "F4GY07sLHpm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "text = generator(\"Once upon a time, there was a curious employee who\", max_length=50)\n",
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUKq6n0kHf74",
        "outputId": "58dbcced-c2ca-4b7c-d958-479523bd1c19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a curious employee who turned up with a lot of notes on the keyboard. He claimed that all of them were completely empty, only five or nine at a time, which was an almost unheard of occurrence. There were\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6. Named Entity Recognition (NER) Models**\n",
        "For extracting entities like names, dates, organizations, etc., from text.\n",
        "\n",
        "* dbmdz/bert-large-cased-finetuned-conll03-english: Fine-tuned on CoNLL-2003 for NER.\n",
        "* dslim/bert-base-NER: Lightweight NER model"
      ],
      "metadata": {
        "id": "tVtHVa7oIMGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
        "text = \"Neependra Khare founded CloudYuga in December 2015\"\n",
        "entities = ner(text)\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsbvTOn5ICip",
        "outputId": "a86d49f3-4746-4a11-fd5a-7a72462fddd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'PER', 'score': np.float32(0.9995653), 'word': 'Neependra Khare', 'start': 0, 'end': 15}, {'entity_group': 'ORG', 'score': np.float32(0.97774523), 'word': 'CloudYuga', 'start': 24, 'end': 33}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**7. Translation Models**\n",
        "For translating text between languages.\n",
        "\n",
        "- Helsinki-NLP/opus-mt-en-de: English-to-German translation.\n",
        "- t5-small, t5-large: Can also be used for translation by prefixing the input with translate English to French:."
      ],
      "metadata": {
        "id": "rdGf1lf1JRTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "translation = translator(\"The employee feedback has been overwhelmingly positive!\")\n",
        "print(translation[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDIYwyZsIWpS",
        "outputId": "8ea80128-f73a-42e5-ea09-a32c94802616"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das Feedback der Mitarbeiter war überwältigend positiv!\n"
          ]
        }
      ]
    }
  ]
}