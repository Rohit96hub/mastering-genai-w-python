{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Text Summary using Huggingface Transformers**"
      ],
      "metadata": {
        "id": "_Xozg0aXjqvv"
      },
      "id": "_Xozg0aXjqvv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate a summary using transformers' model we will first download a dataset."
      ],
      "metadata": {
        "id": "wkzMLcoUF2Nb"
      },
      "id": "wkzMLcoUF2Nb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Downloads the `hrdataset.zip` file from the CloudYuga GitHub repo**\n",
        "\n",
        "Saves it in the current working directory of notebook\n",
        "\n",
        "(e.g., /content/ in Google Colab)."
      ],
      "metadata": {
        "id": "XJ0-4Pp2Eh72"
      },
      "id": "XJ0-4Pp2Eh72"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudyuga/mastering-genai-w-python/raw/refs/heads/main/hrdataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dvINgLO574_K",
        "outputId": "5eb03faa-4daa-4c3e-9b84-5a1e68490f63"
      },
      "id": "dvINgLO574_K",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 17:42:24--  https://github.com/cloudyuga/mastering-genai-w-python/raw/refs/heads/main/hrdataset.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/cloudyuga/mastering-genai-w-python/refs/heads/main/hrdataset.zip [following]\n",
            "--2025-05-21 17:42:24--  https://raw.githubusercontent.com/cloudyuga/mastering-genai-w-python/refs/heads/main/hrdataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9530 (9.3K) [application/zip]\n",
            "Saving to: ‘hrdataset.zip’\n",
            "\n",
            "hrdataset.zip       100%[===================>]   9.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-21 17:42:24 (84.6 MB/s) - ‘hrdataset.zip’ saved [9530/9530]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Unzip `hrdataset.zip` file**\n",
        "- It will automatically create **`hrdataset`** folder in our current working directory (/content/ in Google Colab)"
      ],
      "metadata": {
        "id": "pedXYRVpGHnL"
      },
      "id": "pedXYRVpGHnL"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip hrdataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LS2Fje68MAh",
        "outputId": "921dfca3-1a19-42aa-cfcf-5aaba8cde3ff"
      },
      "id": "7LS2Fje68MAh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  hrdataset.zip\n",
            "   creating: hrdataset/\n",
            "   creating: hrdataset/policies/\n",
            "  inflating: hrdataset/policies/leave_policies.md  \n",
            "  inflating: hrdataset/policies/training_and_development.md  \n",
            "  inflating: hrdataset/policies/employee_benefits.md  \n",
            "  inflating: hrdataset/policies/holiday_calendar.md  \n",
            "  inflating: hrdataset/policies/events_calendar.md  \n",
            "   creating: hrdataset/surveys/\n",
            "  inflating: hrdataset/surveys/Employee_Culture_Survey_Responses.csv  \n",
            "   creating: hrdataset/employees/\n",
            "  inflating: hrdataset/employees/108_Rajesh_Kulkarni.md  \n",
            "  inflating: hrdataset/employees/106_Neha_Malhotra.md  \n",
            "  inflating: hrdataset/employees/103_Anjali_Das.md  \n",
            "  inflating: hrdataset/employees/105_Sunita_Patil.md  \n",
            "  inflating: hrdataset/employees/101_Priya_Sharma.md  \n",
            "  inflating: hrdataset/employees/102_Rohit_Mehra.md  \n",
            "  inflating: hrdataset/employees/104_Karan_Kapoor.md  \n",
            "  inflating: hrdataset/employees/109_Meera_Iyer.md  \n",
            "  inflating: hrdataset/employees/110_Aditya_Jain.md  \n",
            "  inflating: hrdataset/employees/107_Amit_Verma.md  \n",
            "  inflating: hrdataset/employees/payroll_information.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Python Code to read data from dataset**"
      ],
      "metadata": {
        "id": "RS0IIp8_mdC2"
      },
      "id": "RS0IIp8_mdC2"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4186a50-5159-4de9-a793-52387da9a2eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4186a50-5159-4de9-a793-52387da9a2eb",
        "outputId": "7979d643-aebe-47f1-d8fe-d46cb61c1a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Name                   Role          Department  \\\n",
            "0  ** Rajesh Kulkarni                 ** CTO        ** Executive   \n",
            "1       ** Amit Verma                 ** CEO        ** Executive   \n",
            "2       ** Meera Iyer   ** Marketing Manager        ** Marketing   \n",
            "3      ** Aditya Jain    ** Senior Developer               ** IT   \n",
            "4      ** Rohit Mehra   ** Logistics Analyst        ** Logistics   \n",
            "5       ** Anjali Das        ** HR Executive  ** Human Resources   \n",
            "6    ** Neha Malhotra      ** Junior Analyst        ** Logistics   \n",
            "7     ** Karan Kapoor    ** Fleet Supervisor        ** Logistics   \n",
            "8     ** Priya Sharma  ** Operations Manager       ** Operations   \n",
            "9     ** Sunita Patil   ** Finance Executive          ** Finance   \n",
            "\n",
            "    Joining Date  \n",
            "0  ** 2017-11-15  \n",
            "1  ** 2016-02-01  \n",
            "2  ** 2020-02-20  \n",
            "3  ** 2019-06-10  \n",
            "4  ** 2020-08-22  \n",
            "5  ** 2021-05-10  \n",
            "6  ** 2023-07-01  \n",
            "7  ** 2018-11-03  \n",
            "8  ** 2019-03-15  \n",
            "9  ** 2022-01-17  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing markdown files\n",
        "markdown_dir = \"hrdataset/employees\"\n",
        "\n",
        "# Parse markdown files into a DataFrame\n",
        "employee_data = []\n",
        "for filename in os.listdir(markdown_dir):\n",
        "    if filename.endswith(\".md\"):\n",
        "        with open(os.path.join(markdown_dir, filename), \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            profile = {}\n",
        "            for line in lines:\n",
        "                if line.startswith(\"- **Name:**\"):\n",
        "                    profile[\"Name\"] = line.split(\":\")[1].strip()\n",
        "                elif line.startswith(\"- **Role:**\"):\n",
        "                    profile[\"Role\"] = line.split(\":\")[1].strip()\n",
        "                elif line.startswith(\"- **Department:**\"):\n",
        "                    profile[\"Department\"] = line.split(\":\")[1].strip()\n",
        "                elif line.startswith(\"- **Joining Date:**\"):\n",
        "                    profile[\"Joining Date\"] = line.split(\":\")[1].strip()\n",
        "            if profile:\n",
        "                employee_data.append(profile)\n",
        "\n",
        "# Convert to DataFrame\n",
        "employee_df = pd.DataFrame(employee_data)\n",
        "print(employee_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Summarize the content**"
      ],
      "metadata": {
        "id": "eyGrj68vIEnm"
      },
      "id": "eyGrj68vIEnm"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fadd6d83-d945-4dd8-9d82-a1cf95584690",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "fadd6d83-d945-4dd8-9d82-a1cf95584690",
        "outputId": "220e6148-da68-4f30-b133-27171445cd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "443ab33af5ee4f92976c9da66547467e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06bcbd6d7e08419e9f1329c5cf1a05b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ebfab2ea0434665b204881ff8d50f8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8116f53c5824b4188c6f03b08fe6244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "009c664d8e2d4a1b9b4d658ea054a66f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d7cfc9beee344c38ea66c13e21edfd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 50, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of New York for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Combine employee details for a specific department\n",
        "operations_data = \" \".join([\n",
        "    f\"{row['Name']} is the {row['Role']} in {row['Department']}, joined on {row['Joining Date']}.\"\n",
        "    for _, row in employee_df.iterrows() if row['Department'] == \"Operations\"\n",
        "])\n",
        "\n",
        "# Summarize the data\n",
        "summary = summarizer(operations_data, max_length=50, min_length=10, do_sample=False)\n",
        "print(\"Summary:\", summary[0]['summary_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Example: Policy Summary in 50 words**"
      ],
      "metadata": {
        "id": "Oe2oFsyFkaiV"
      },
      "id": "Oe2oFsyFkaiV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Read Policies**"
      ],
      "metadata": {
        "id": "mjsuVSWfLKpg"
      },
      "id": "mjsuVSWfLKpg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all content\n",
        "import os\n",
        "\n",
        "policy_dir = \"hrdataset/policies\"\n",
        "all_policies_content = {}\n",
        "\n",
        "for filename in os.listdir(policy_dir):\n",
        "    if filename.endswith(\".md\"):\n",
        "        with open(os.path.join(policy_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = f.readlines()\n",
        "            if not lines:\n",
        "                continue\n",
        "            # First line is the title\n",
        "            title = lines[0].strip().replace(\"#\", \"\").strip()\n",
        "            # Remaining lines as content\n",
        "            content = \" \".join([line.strip() for line in lines[1:] if line.strip()])\n",
        "            all_policies_content[title] = content\n",
        "\n",
        "# Optional: View all titles\n",
        "print(\"✅ Loaded Policies:\\n\", list(all_policies_content.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4S6XL8G9DmS",
        "outputId": "14b29bd7-bf53-484d-b9c0-423d40753d9d"
      },
      "id": "S4S6XL8G9DmS",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Policies:\n",
            " ['Leave Policies', 'Training and Development', 'Employee Benefits', 'Holiday Calendar', 'Events and Holiday Calendar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Print Policies content**"
      ],
      "metadata": {
        "id": "YX_07z50LVjp"
      },
      "id": "YX_07z50LVjp"
    },
    {
      "cell_type": "code",
      "source": [
        "for title, content in all_policies_content.items():\n",
        "    print(f\"\\n🗂️ {title}\\n{'=' * (len(title) + 4)}\\n{content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I-ByQ9zBTJM",
        "outputId": "171fb6b6-8233-464a-f0cb-91142d6d258a"
      },
      "id": "5I-ByQ9zBTJM",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🗂️ Leave Policies\n",
            "==================\n",
            "- **Annual Leave:** 18 days of paid leave per year, accrued monthly. - **Sick Leave:** 12 days of paid leave for medical reasons per year. - **Maternity Leave:** 6 months of paid leave for expecting mothers. - **Paternity Leave:** 15 days of paid leave for new fathers.L - **Compensatory Leave:** Leave granted for working on weekends or holidays.\n",
            "\n",
            "\n",
            "🗂️ Training and Development\n",
            "============================\n",
            "| Employee ID | Name           | Courses Taken                          | Completion Date | Certifications Awarded      | |-------------|----------------|----------------------------------------|-----------------|----------------------------| | 101         | Priya Sharma   | Leadership in Operations              | 2022-12-10      | Certified Operations Manager | | 102         | Rohit Mehra    | Data Analytics for Logistics          | 2021-11-15      | Certified Logistics Analyst | | 103         | Anjali Das     | HR Management Essentials              | 2023-03-05      | Certified HR Professional   |\n",
            "\n",
            "\n",
            "🗂️ Employee Benefits\n",
            "=====================\n",
            "- **Health Insurance:** Covers employee and dependents up to ₹5,00,000. - **Provident Fund:** 12% of basic salary contributed to the PF account. - **Gratuity:** Paid on retirement/resignation based on tenure. - **Travel Allowance:** Reimbursement for official travel expenses. - **Skill Development:** Reimbursement for approved certifications/training costs.\n",
            "\n",
            "\n",
            "🗂️ Holiday Calendar\n",
            "====================\n",
            "| Festival Name          | Date       | Day         | |------------------------|------------|-------------| | Republic Day          | 2023-01-26 | Thursday    | | Holi                 | 2023-03-08 | Wednesday   | | Good Friday          | 2023-04-07 | Friday      | | Eid al-Fitr          | 2023-04-22 | Saturday    | | Independence Day     | 2023-08-15 | Tuesday     | | Raksha Bandhan       | 2023-08-30 | Wednesday   | | Ganesh Chaturthi     | 2023-09-19 | Tuesday     | | Diwali               | 2023-11-12 | Sunday      | | Christmas            | 2023-12-25 | Monday      | | Makar Sankranti      | 2023-01-14 | Saturday    |\n",
            "\n",
            "\n",
            "🗂️ Events and Holiday Calendar\n",
            "===============================\n",
            "| Event Name            | Date       | Time     | Location        | Participants           | |-----------------------|------------|----------|-----------------|------------------------| | Annual Company Meet   | 2023-12-15 | 10:00 AM | Mumbai Office   | All employees          | | Health Camp           | 2023-11-10 | 09:00 AM | Bangalore Office| All employees          | | Team Building Event   | 2023-09-05 | 02:00 PM | Goa Resort      | Operations Team        |\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Summarize each Policy using Bart model**"
      ],
      "metadata": {
        "id": "Gy4T1IR5LrXN"
      },
      "id": "Gy4T1IR5LrXN"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load summarizer\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Loop through and summarize each policy section\n",
        "for title, content in all_policies_content.items():\n",
        "    print(f\"\\n📄 {title}\")\n",
        "    # BART has a token limit (max ~1024 tokens); trim if too long\n",
        "    if len(content.split()) > 900:\n",
        "        content = \" \".join(content.split()[:900])  # truncate safely\n",
        "    summary = summarizer(content, max_length=60, min_length=15, do_sample=False)\n",
        "    print(\"📝 Summary:\", summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e95vInTskZ-V",
        "outputId": "d37ad7f5-555b-48f1-a234-3ac91b2f65bd"
      },
      "id": "e95vInTskZ-V",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📄 Leave Policies\n",
            "📝 Summary: L - Annual Leave:** 18 days of paid leave per year, accrued monthly. - Maternity Leave: ** 6 months ofpaid leave for expecting mothers. - Paternity leave:** 15 days of Paid Leave for new fathers. - Compensatory Leave:  Leave granted for\n",
            "\n",
            "📄 Training and Development\n",
            "📝 Summary: Employee ID is the name and name of the person holding the employee ID. The employee ID is also the name of that person's course of study. Courses taken include Leadership in Operations, HR Management Essentials, Data Analytics for Logistics and HR Professional.\n",
            "\n",
            "📄 Employee Benefits\n",
            "📝 Summary: Health Insurance:** Covers employee and dependents up to ₹5,00,000. Provident Fund:** 12% of basic salary contributed to the PF account. Gratuity:** Paid on retirement/resignation based on tenure.\n",
            "\n",
            "📄 Holiday Calendar\n",
            "📝 Summary: Holi, Diwali, Raksha Bandhan, Ganesh Chaturthi, Makar Sankranti, Eid al-Fitr, Christmas, Independence Day, Good Friday, Republic Day are among the festivals on this list.\n",
            "\n",
            "📄 Events and Holiday Calendar\n",
            "📝 Summary: Annual Company Meet: 2023-12-15 | 10:00 AM | Mumbai Office. Health Camp: 2024-11-10 | 09:00am | Bangalore Office. Team Building Event: 2025-09-05 | 02:00 PM | Goa Resort\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
