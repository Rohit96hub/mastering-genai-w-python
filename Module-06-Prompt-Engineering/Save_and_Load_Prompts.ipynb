{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Store prompt as .pkl file**"
      ],
      "metadata": {
        "id": "ZaeBEWDUkByD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install required package\n",
        "!pip install langchain langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LWPowMwohbVo",
        "outputId": "2dc370d0-74d9-4b74-eebc-d2b82bef32ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.70.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.12 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the API key from Colab's secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "lXpix2-wi0Sz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "2U7sFapfi6-D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AdEroWdLer9T"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import necessary libraries\n",
        "import pickle\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create HR-related PromptTemplate\n",
        "hr_prompt = PromptTemplate(\n",
        "    input_variables=[\"candidate_name\", \"job_title\"],\n",
        "    template=\"Write a friendly HR email to {candidate_name} congratulating them on being shortlisted for the role of {job_title}.\"\n",
        ")"
      ],
      "metadata": {
        "id": "F90q_10-jLq4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Save the prompt using pickle\n",
        "with open(\"hr_prompt.pkl\", \"wb\") as f:\n",
        "    pickle.dump(hr_prompt, f)\n",
        "\n",
        "print(\"‚úÖ Prompt saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT6yz-LbjSoa",
        "outputId": "27137e38-fd80-4fab-d48e-d42a1ef81a87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prompt saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Load the prompt from the pickle file\n",
        "with open(\"hr_prompt.pkl\", \"rb\") as f:\n",
        "    loaded_prompt = pickle.load(f)\n",
        "\n",
        "print(\"‚úÖ Prompt loaded successfully!\")\n",
        "print(\"üìù Template:\", loaded_prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phII42SDjVvL",
        "outputId": "9ffc1129-55d1-4f0f-850f-6a454e61b228"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prompt loaded successfully!\n",
            "üìù Template: Write a friendly HR email to {candidate_name} congratulating them on being shortlisted for the role of {job_title}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Format the prompt with inputs\n",
        "formatted_prompt = loaded_prompt.format(candidate_name=\"Rohit Sharma\", job_title=\"Senior Data Analyst\")\n",
        "print(\"\\nüßæ Final Prompt:\\n\", formatted_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RAb1Jf7jYM9",
        "outputId": "ff1fdc96-4a57-47aa-eecd-23f75796b9af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßæ Final Prompt:\n",
            " Write a friendly HR email to Rohit Sharma congratulating them on being shortlisted for the role of Senior Data Analyst.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Call the LLM to get a response\n",
        "response = llm.invoke(formatted_prompt)\n",
        "print(\"\\nüì© LLM Response:\\n\", response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6wvtXkSjaVv",
        "outputId": "fbbc08dd-2e6d-4798-a336-8dd1920aad1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì© LLM Response:\n",
            " Subject: Congratulations on Your Shortlisting for the Senior Data Analyst Role!\n",
            "\n",
            "Dear Rohit,\n",
            "\n",
            "I hope this message finds you well!\n",
            "\n",
            "I am thrilled to inform you that you have been shortlisted for the Senior Data Analyst position. Congratulations! Your qualifications and experience stood out to our hiring team, and we are excited to move forward in the process with you.\n",
            "\n",
            "We believe that your skills will greatly contribute to our team, and we look forward to discussing your application in more detail. Please keep an eye out for an email from us regarding the next steps in the interview process.\n",
            "\n",
            "Once again, congratulations on this achievement! If you have any questions in the meantime, feel free to reach out.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Job Title]  \n",
            "[Company Name]  \n",
            "[Your Contact Information]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Store Prompt as .json file**"
      ],
      "metadata": {
        "id": "TmSlUwxvkdkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "I-yhtJOYk57m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Save to JSON\n",
        "prompt_data = {\n",
        "    \"input_variables\": hr_prompt.input_variables,\n",
        "    \"template\": hr_prompt.template\n",
        "}\n",
        "with open(\"hr_prompt.json\", \"w\") as f:\n",
        "    json.dump(prompt_data, f)\n",
        "\n",
        "print(\"‚úÖ Prompt saved as JSON!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Evoimbk7k_",
        "outputId": "30da52a3-a94f-4622-c29e-4d77e0fb5fc0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prompt saved as JSON!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Load from JSON\n",
        "with open(\"hr_prompt.json\", \"r\") as f:\n",
        "    loaded_data = json.load(f)\n",
        "\n",
        "print(\"‚úÖ Prompt loaded from JSON!\")\n",
        "print(\"üìù Template:\", loaded_prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-7spZe5lY6_",
        "outputId": "5bb4abf2-c030-4be6-9c01-a8cc0d4984b4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prompt loaded from JSON!\n",
            "üìù Template: Write a friendly HR email to {candidate_name} congratulating them on being shortlisted for the role of {job_title}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Format and Use with LLM\n",
        "formatted_prompt = loaded_prompt.format(candidate_name=\"Anjali Verma\", job_title=\"Product Manager\")\n",
        "\n",
        "response = llm.invoke(formatted_prompt)\n",
        "print(\"\\nüì© LLM Response:\\n\", response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_7ChL7uld_o",
        "outputId": "d0db73e4-0aff-4306-9dbf-39e5fd86abb3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì© LLM Response:\n",
            " Subject: Congratulations on Your Shortlisting for the Product Manager Role!\n",
            "\n",
            "Dear Anjali,\n",
            "\n",
            "I hope this message finds you well!\n",
            "\n",
            "I am thrilled to share the exciting news that you have been shortlisted for the Product Manager position with us. Your skills and experiences stood out to our team, and we are eager to move forward in the selection process.\n",
            "\n",
            "This is a fantastic opportunity for us to learn more about your vision and ideas, and we believe you could be a great fit for our team. We will be in touch shortly to discuss the next steps and to schedule your interview.\n",
            "\n",
            "Once again, congratulations on this achievement! We look forward to speaking with you soon.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Job Title]  \n",
            "[Your Company]  \n",
            "[Your Contact Information]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNy1KxSAlPLK",
        "outputId": "e4a09f6e-f032-4669-e89e-e3858622bf9e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a friendly HR email to Anjali Verma congratulating them on being shortlisted for the role of Product Manager.\n"
          ]
        }
      ]
    }
  ]
}